# ACL
## nlp的可解释性与分析
### 2023
* Entity Tracking in Language Models

## 对抗攻击和鲁棒性

### 2022
* Adversarial Authorship Attribution for Deobfuscation[[PDF](https://aclanthology.org/2022.acl-long.509.pdf)][[Code](https://github.com/reginazhai/Authorship-Deobfuscation)]

* Adversarial Soft Prompt Tuning for Cross-Domain Sentiment Analysis[[PDF](https://aclanthology.org/2022.acl-long.174.pdf)]

* Flooding-X: Improving BERT’s Resistance to Adversarial Attacks via LossRestricted Fine-Tuning[[PDF](https://aclanthology.org/2022.acl-long.386.pdf)]

* From the Detection of Toxic Spans in Online Discussions to the Analysis of Toxic-to-Civil Transfer[[PDF](https://aclanthology.org/2022.acl-long.259.pdf)][[Code](https://github.com/ipavlopoulos/toxic_spans)]

* Imputing Out-of-Vocabulary Embeddings with LOVE Makes Language Models Robust with Little Cost[[PDF](https://arxiv.org/pdf/2203.07860.pdf)][[Code](https://github.com/tigerchen52/LOVE)]

* ParaDetox: Detoxification with Parallel Data[[PDF](https://aclanthology.org/2022.acl-long.469.pdf)][[Code](https://github.com/s-nlp/paradetox)]

* Pass off Fish Eyes for Pearls: Attacking Model Selection of Pre-trained Models[[PDF](https://aclanthology.org/2022.acl-long.347.pdf)][[Code](https://github.com/thunlp/Model-Selection-Attack)]

* SHIELD: Defending Textual Neural Networks against Multiple Black-Box[[PDF](https://aclanthology.org/2022.acl-long.459.pdf)][[Code](https://github.com/lethaiq/shield-defend-adversarial-texts)]

* Towards Robustness of Text-to-SQL Models Against Natural and Realistic Adversarial Table Perturbation[[PDF](https://aclanthology.org/2022.acl-long.142.pdf)][[Code](https://github.com/microsoft/ContextualSP)]

* ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection[[PDF](https://aclanthology.org/2022.acl-long.234.pdf)][[Code](https://github.com/microsoft/ToxiGen)]

### 2021
* Improving Gradient-based Adversarial Training for Text Classification by Contrastive Learning and Auto-Encoder[[PDF](https://arxiv.org/pdf/2109.06536v1.pdf)]

## 鲁棒性提高公平性
### 2021
* Does Robustness Improve Fairness? Approaching Fairness with Word Substitution Robustness Methods for Text Classification[[PDF](https://arxiv.org/pdf/2106.10826.pdf)]

## 中文
### 2021
* Correcting Chinese Spelling Errors with Phonetic Pre-training
* Dynamic Connected Networks for Chinese Spelling Check
## 关于语言模型的攻防
### 2023
* Language model acceptability judgements are not always robust to context[[PDF]()]
### 2021
* BERT-Defense: A Probabilistic Model Based on BERT to Combat Cognitively Inspired Orthographic Adversarial Attacks[[PDF](https://arxiv.org/pdf/2106.01452.pdf)]
* Defending Pre-trained Language Models from Adversarial Word Substitutions Without Performance Sacrifice[[PDF](https://arxiv.org/pdf/2105.14553.pdf)]
## 优化器
### 2023
* CAME: Confidence-guided Adaptive Memory Efficient Optimization[[PDF](https://arxiv.org/pdf/2307.02047.pdf)][Code](https://github.com/yangluo7/CAME)]
## 分类器
### 2023
* Linear Classifier: An Often-Forgotten Baseline for Text Classification
