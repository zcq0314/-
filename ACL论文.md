# ACL
## 对抗攻击和鲁棒性

### 2022
* Adversarial Authorship Attribution for Deobfuscation[[PDF](https://aclanthology.org/2022.acl-long.509.pdf)][[Code](https://github.com/reginazhai/Authorship-Deobfuscation)]

* Adversarial Soft Prompt Tuning for Cross-Domain Sentiment Analysis[[PDF](https://aclanthology.org/2022.acl-long.174.pdf)]

* Flooding-X: Improving BERT’s Resistance to Adversarial Attacks via LossRestricted Fine-Tuning[[PDF](https://aclanthology.org/2022.acl-long.386.pdf)]

* From the Detection of Toxic Spans in Online Discussions to the Analysis of Toxic-to-Civil Transfer[[PDF](https://aclanthology.org/2022.acl-long.259.pdf)][[Code](https://github.com/ipavlopoulos/toxic_spans)]

* Imputing Out-of-Vocabulary Embeddings with LOVE Makes Language Models Robust with Little Cost[[PDF](https://arxiv.org/pdf/2203.07860.pdf)][[Code](https://github.com/tigerchen52/LOVE)]

* ParaDetox: Detoxification with Parallel Data[[PDF](https://aclanthology.org/2022.acl-long.469.pdf)][[Code](https://github.com/s-nlp/paradetox)]

* Pass off Fish Eyes for Pearls: Attacking Model Selection of Pre-trained Models[[PDF](https://aclanthology.org/2022.acl-long.347.pdf)][[Code](https://github.com/thunlp/Model-Selection-Attack)]

* SHIELD: Defending Textual Neural Networks against Multiple Black-Box[[PDF](https://aclanthology.org/2022.acl-long.459.pdf)][[Code](https://github.com/lethaiq/shield-defend-adversarial-texts)]

* Towards Robustness of Text-to-SQL Models Against Natural and Realistic Adversarial Table Perturbation[[PDF](https://aclanthology.org/2022.acl-long.142.pdf)][[Code](https://github.com/microsoft/ContextualSP)]

* ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection[[PDF](https://aclanthology.org/2022.acl-long.234.pdf)][[Code](https://github.com/microsoft/ToxiGen)]
